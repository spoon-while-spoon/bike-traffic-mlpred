{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlHXvm2UajHpYJL1CUa0U7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spoon-while-spoon/bike-traffic-mlpred/blob/main/ml_car_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1RbQOiCZphEB"
      },
      "outputs": [],
      "source": [
        "# Importieren der benötigten Bibliotheken\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True) # Setzt Standardfarbcodes für Seaborn-Plots\n",
        "\n",
        "# Konvertiert einen Integer-Zeitstempel in ein Datums-/Zeitformat\n",
        "def parse_date(date_int):\n",
        "    date_str = str(date_int) # Konvertiert den Integer in einen String\n",
        "    return pd.to_datetime(date_str, format='%Y%m%d%H')\n",
        "\n",
        "# Einlesen der CSV-Dateien sowie erste Anpassungen\n",
        "wind_df = pd.read_csv(\"wind.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['eor', 'STATIONS_ID', 'QUALITAETS_NIVEAU', 'STRUKTUR_VERSION', 'WINDRICHTUNG'], axis=1)\n",
        "sun_df = pd.read_csv(\"sun.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['STATIONS_ID', 'QUALITAETS_NIVEAU', 'STRUKTUR_VERSION', 'eor'], axis=1)\n",
        "precipation_df = pd.read_csv(\"precipation.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['STATIONS_ID', 'QUALITAETS_NIVEAU', 'STRUKTUR_VERSION', 'eor'], axis=1)\n",
        "airpressure_df = pd.read_csv(\"airpressure.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['STATIONS_ID', 'QUALITAETS_NIVEAU', 'STRUKTUR_VERSION', 'LUFTDRUCK_STATIONSHOEHE', 'eor'], axis=1)\n",
        "\n",
        "air_temp_df = pd.read_csv(\"air_temp.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['STATIONS_ID', 'QUALITAETS_NIVEAU', 'STRUKTUR_VERSION', 'LUFTTEMPERATUR_FALSCH', 'STRAHLUNGSTEMPERATUR', 'eor'], axis=1)\n",
        "air_temp_df['LUFTTEMPERATUR_RICHTIG'] = pd.to_numeric(air_temp_df['LUFTTEMPERATUR_RICHTIG'], errors='coerce')\n",
        "air_temp_df['REL_FEUCHTE'] = pd.to_numeric(air_temp_df['REL_FEUCHTE'], errors='coerce')\n",
        "air_temp_df = air_temp_df[(air_temp_df['LUFTTEMPERATUR_RICHTIG'] >= -25) & (air_temp_df['LUFTTEMPERATUR_RICHTIG'] <= 45) & (air_temp_df['REL_FEUCHTE'] >= 0) & (air_temp_df['REL_FEUCHTE'] <= 99)]\n",
        "\n",
        "radverkehr_df = pd.read_csv(\"radverkehr_final.csv\", sep=\";\", index_col=1, parse_dates=True, date_parser=parse_date).drop(['datum_rad'], axis=1).assign(RAD_gesamt=lambda df: df['NORD'] + df['SUED'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kombinieren & Bereinigen\n",
        "\n",
        "Hier werden unsere erstellten Dataframes zu einem **kombiniert** `(pd.concat)` und anschließend  **bereinigt** von unvollständigen Datensätzen.\n",
        "\n",
        "Datenreihen zu denen nicht alle Daten vorliegen werden komplett entfernt durch `dropna()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "z4nyF3GOk-ND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = pd.concat([wind_df, sun_df, precipation_df, airpressure_df, air_temp_df, radverkehr_df], axis=1).dropna()"
      ],
      "metadata": {
        "id": "GJaCQ58BnAuq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ergebnis\n",
        "Mit `print(df_cleaned.head())` lassen sich die ersten Datenreihen überprüfgen.\n",
        "Die Anzahl der Übrig gebliebenen Datensätze kann mit `num_rows = len(df_cleaned)` gezählt und dann ausgeben werden.  "
      ],
      "metadata": {
        "id": "urH_dm2bmNgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_cleaned.head())\n",
        "print(\"\\n--------------------------------------------------\")\n",
        "print(\"Gesamtzahl der bereinigten Datensätze:\", num_rows)\n",
        "print(\"--------------------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "ARsdIF3bkd7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}